{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0324b56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data Handler\n",
    "Soubour urƒçen√Ω k manipulaci s csv soubory, neboli p≈ô√≠slu≈°n√Ωmi l√©ka≈ôsk√Ωmi zpr√°vami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05544dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scripts import config\n",
    "import os\n",
    "import markdown\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "from src import analyzator as an\n",
    "\n",
    "base_root = config.CSV_DATA_ROOT\n",
    "files = os.listdir(base_root)\n",
    "crohn = os.path.join(base_root, files[0])\n",
    "crohn_2 = os.path.join(base_root, files[1])\n",
    "stroke = os.path.join(base_root, files[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a27a3",
   "metadata": {},
   "source": [
    "## Testovac√≠ skript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9629e7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zk.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/medical_reports/002_crohn.txt\", 'r', encoding='utf-8') as fr:\n",
    "    input_text = fr.read()\n",
    "\n",
    "an.analyze_text(input_text, \"zk.txt\")\n",
    "#res = an.detect_sections(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv(stroke)\n",
    "\n",
    "# 1Ô∏è‚É£ Z√≠sk√°me \"ƒçist√Ω n√°zev\" z title (odstran√≠me prefixy jako \"041/000 - \" apod.)\n",
    "df[\"clean_title\"] = df[\"title\"].str.extract(r\"-\\s*(.*)$\")[0].str.strip()\n",
    "# 2Ô∏è‚É£ Poƒçet slov v textu\n",
    "df[\"word_count\"] = df[\"text\"].fillna(\"\").str.split().str.len()\n",
    "\n",
    "# 3Ô∏è‚É£ Filtrovat jen ty ≈ô√°dky, kter√© maj√≠ clean_title v TITLES_CROHN\n",
    "filtered = df[df[\"clean_title\"].isin(config.TITLES_STROKE)]\n",
    "\n",
    "# 4Ô∏è‚É£ Spoƒç√≠tat pr≈Ømƒõrn√Ω / celkov√Ω poƒçet slov pro ka≈æd√Ω title\n",
    "summary = (\n",
    "    filtered.groupby(\"clean_title\")[\"word_count\"]\n",
    "    .mean()  # nebo .sum(), podle pot≈ôeby\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"word_count\", ascending=False)\n",
    ")\n",
    "\n",
    "with open(\"summary_c1.txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(summary.to_string())\n",
    "    f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed20388",
   "metadata": {},
   "source": [
    "### Script k nalezen√≠ \"title\"\n",
    "Funkce m√° za √∫kol odstranit ƒç√≠sla a znaky ze sloupce 'title' a ponechat jen skuteƒçn√Ω n√°zev vy≈°et≈ôen√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f2c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    print(str(row['title']))# ka≈æd√° ≈ô√°dka = Series s hodnotami\n",
    "    if config.TITLES_CROHN[2] in str(row['title']):  # p≈ô√≠stup ke sloupci 'title'\n",
    "        texts.append(str(row['text']))  # p≈ô√≠stup ke sloupci 'text'\n",
    "        \n",
    "with open(\"output.txt\", 'w', encoding='utf-8') as f:\n",
    "    for text in texts:\n",
    "        f.write(text)\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"---------------------------------------------------------------------\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55245ee",
   "metadata": {},
   "source": [
    "### Testov√°n√≠ spr√°vn√Ωch slov\n",
    "Naƒçtu jednotliv√° slova ze zad√°n√≠ a z v√Ωstup≈Ø a zjist√≠m kolik slov si model vymyslel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04953b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = config.REPORTS_ROOT\n",
    "result_path = config.RESULT_ROOT\n",
    "\n",
    "# 1Ô∏è‚É£ Naƒçten√≠ slov z medical reportu\n",
    "words = []\n",
    "text_file = os.path.join(text_path, \"01_crohn.txt\")\n",
    "\n",
    "with open(text_file, \"r\", encoding=\"utf-8\") as fr:\n",
    "    for line in fr:\n",
    "        words.extend(line.strip().split())\n",
    "\n",
    "# Vytvo≈ô mno≈æinu pro rychl√© porovn√°n√≠ (mal√° p√≠smena)\n",
    "valid_words = set(word.lower().strip(\",.()[];:!?\") for word in words if word.strip())\n",
    "\n",
    "print(f\"‚úÖ Naƒçteno {len(valid_words)} unik√°tn√≠ch slov z {text_file}\\n\")\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ Naƒçten√≠ markdown soubor≈Ø z result_path\n",
    "files = [f for f in os.listdir(result_path) if os.path.isfile(os.path.join(result_path, f))]\n",
    "markdown_html_results = {}\n",
    "\n",
    "for file in files:\n",
    "    if file.endswith(\".md\") and \"r01\" in file:\n",
    "        path = os.path.join(result_path, file)\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            md_text = f.read()\n",
    "            html_content = markdown.markdown(md_text)\n",
    "            markdown_html_results[file] = html_content\n",
    "\n",
    "print(f\"‚úÖ Naƒçteno {len(markdown_html_results)} markdown soubor≈Ø\\n\")\n",
    "\n",
    "\n",
    "# 3Ô∏è‚É£ Porovn√°n√≠ slov z md soubor≈Ø se slovn√≠ z√°sobou reportu\n",
    "unknown_words_total = set()\n",
    "unknown_words_llm = {}\n",
    "\n",
    "\n",
    "for filename, html_content in markdown_html_results.items():\n",
    "    # Odstra≈à HTML tagy a rozbij text na slova\n",
    "    text_only = re.sub(r\"<[^>]+>\", \"\", html_content)\n",
    "    md_words = re.findall(r\"\\b\\w+\\b\", text_only.lower())\n",
    "\n",
    "    unknown_words = set(w for w in md_words if w not in valid_words)\n",
    "    unknown_words_total.update(unknown_words)\n",
    "    unknown_words_llm[filename] = unknown_words\n",
    "    \n",
    "    print(f\"üìÑ {filename}: {len(unknown_words)} nezn√°m√Ωch slov\")\n",
    "\n",
    "print(\"==============================================\")\n",
    "print(f\"üîç Celkem nalezeno {len(unknown_words_total)} unik√°tn√≠ch 'vymy≈°len√Ωch' slov.\")\n",
    "print(\"==============================================\")\n",
    "\n",
    "output_path = \"unknown_words.txt\"\n",
    "with open(output_path, 'w', encoding='utf-8') as wr:\n",
    "    for key, values in unknown_words_llm.items():\n",
    "        wr.write(f\"------------ {key} ------------\\n\")\n",
    "        for _ in range(len(unknown_words_llm[key])):\n",
    "            wr.write(unknown_words_llm[key].pop())\n",
    "            wr.write(\"\\n\")\n",
    "        wr.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f5cb9",
   "metadata": {},
   "source": [
    "### Vytvo≈ôen√≠ txt fil≈Ø z doccana\n",
    "Vezme JSON z doccana a vytvo≈ô√≠ txt soubory s anotovan√Ωmi slovy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedbe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: vlo≈æ cestu k JSON souboru:\n",
    "INPUT_FILE = \"admin.jsonl\"\n",
    "\n",
    "# OUTPUT: slo≈æka pro v√Ωsledn√© txt soubory\n",
    "OUTPUT_DIR = config.TXT_DATA_ROOT\n",
    "\n",
    "# Naƒçten√≠ v≈°ech ≈ô√°dk≈Ø JSON (ka≈æd√Ω ≈ô√°dek = jeden dokument)\n",
    "records = []\n",
    "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            records.append(json.loads(line))\n",
    "\n",
    "# Slovn√≠k: label ‚Üí seznam text≈Ø\n",
    "labels_dict = {}\n",
    "\n",
    "# Zpracov√°n√≠ v≈°ech dokument≈Ø\n",
    "for record in records:\n",
    "    text = record[\"text\"]\n",
    "    for start, end, label in record[\"label\"]:\n",
    "        extracted = text[start:end]\n",
    "\n",
    "        if label not in labels_dict:\n",
    "            labels_dict[label] = []\n",
    "        labels_dict[label].append(extracted)\n",
    "\n",
    "# Ulo≈æen√≠ do txt soubor≈Ø\n",
    "for label, items in labels_dict.items():\n",
    "    # Bez zak√°zan√Ωch znak≈Ø v n√°zvu souboru\n",
    "    filename = label.replace(\"/\", \"_\") + \".txt\"\n",
    "    path = os.path.join(OUTPUT_DIR, filename)\n",
    "\n",
    "    uniques = []\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in items:\n",
    "            if item not in uniques:\n",
    "                f.write(item.strip() + \"\\n\")\n",
    "                uniques.append(item)\n",
    "\n",
    "print(\"Hotovo! Souborov√© v√Ωstupy jsou ve slo≈æce:\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mre_venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
